{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Tworzenie modelu klasyfikującego**"
      ],
      "metadata": {
        "id": "p650vVdXNFMz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mf5MOgFYs48X"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import scipy.io as sc\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Załadowanie pliku .mat zawierającego wszystkie wzorce\n",
        "oraz ustawienie odpowiedni wzorców z pliku .mat"
      ],
      "metadata": {
        "id": "U6hmFLcYav7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.io as sc\n",
        "import math\n",
        "import numpy as np\n",
        "import random as rd\n",
        "y = sc.loadmat(\"/content/drive/MyDrive/bachelor_thesis_detection/label.mat\")\n",
        "X = sc.loadmat(\"/content/drive/MyDrive/bachelor_thesis_detection (1)/patternData.mat\")\n",
        "Z = sc.loadmat(\"/content/drive/MyDrive/bachelor_thesis_detection/scan_python.mat\")\n",
        "data = X.items()\n",
        "label = y.items()\n",
        "frame = Z.items()\n",
        "listData = list(data)\n",
        "listLabel = list(label)\n",
        "listFrame = list(frame)\n",
        "X = np.array(listData)\n",
        "y = np.array(listLabel)\n",
        "Z = np.array(listFrame)\n",
        "\n",
        "for i in range(35):\n",
        "    for j in range(360):\n",
        "        if X[3,1][i][j] == 99:\n",
        "            X[3,1][i][j] = 0\n",
        "\n",
        "for j in range(360):\n",
        "     if Z[3,1][1][j] == 99:\n",
        "         Z[3,1][1][j] = 0\n",
        "\n",
        "stationL1_05_pat = Z[3,1][1][0:58] \n",
        "stationL1_10_pat = X[3,1][17][0:36]\n",
        "stationL1_15_pat = X[3,1][8][0:26]\n",
        "stationL1_20_pat = X[3,1][26][0:20]\n",
        "\n",
        "\n",
        "stationM1_05_pat = X[3,1][2][0:74] \n",
        "stationM1_10_pat = X[3,1][20][0:41]\n",
        "stationM1_15_pat = X[3,1][11][0:28]\n",
        "stationM1_20_pat = X[3,1][29][0:21]\n",
        "\n",
        "\n",
        "stationR1_05_pat = X[3,1][5][0:80] \n",
        "stationR1_10_pat = X[3,1][23][0:44]\n",
        "stationR1_15_pat = X[3,1][14][0:30]\n",
        "stationR1_20_pat = X[3,1][32][0:23]\n",
        "\n",
        "\n",
        "## Station 2\n",
        "stationL2_05_pat = X[3,1][0][0:40] \n",
        "stationL2_10_pat = X[3,1][18][0:21]\n",
        "stationL2_15_pat = X[3,1][9][0:15]\n",
        "stationL2_20_pat = X[3,1][27][0:12]\n",
        "\n",
        "\n",
        "stationM2_05_pat = X[3,1][3][0:42] \n",
        "stationM2_10_pat = X[3,1][22][0:22]\n",
        "stationM2_15_pat = X[3,1][12][0:15]\n",
        "stationM2_20_pat = X[3,1][30][0:11]\n",
        "\n",
        "\n",
        "stationR2_05_pat = X[3,1][6][0:44] \n",
        "stationR2_10_pat = X[3,1][24][0:21]\n",
        "stationR2_15_pat = X[3,1][15][0:15]\n",
        "stationR2_20_pat = X[3,1][33][0:12]\n",
        "\n",
        "\n",
        "## Station 3\n",
        "stationL3_05_pat = X[3,1][1][0:65] \n",
        "stationL3_10_pat = X[3,1][19][0:42]\n",
        "stationL3_15_pat = X[3,1][10][0:33]\n",
        "stationL3_20_pat = X[3,1][28][0:27]\n",
        "\n",
        "\n",
        "stationM3_05_pat = X[3,1][4][0:72] \n",
        "stationM3_10_pat = X[3,1][22][0:48]\n",
        "stationM3_15_pat = X[3,1][13][0:36]\n",
        "stationM3_20_pat = X[3,1][31][0:29]\n",
        "\n",
        "\n",
        "stationR3_05_pat = X[3,1][7][0:85] \n",
        "stationR3_10_pat = X[3,1][25][0:21]\n",
        "stationR3_15_pat = X[3,1][16][0:38]\n",
        "stationR3_20_pat = X[3,1][34][0:30]\n",
        "\n",
        "#### Noise frames ###\n",
        "## Station 1\n",
        "\n",
        "stationL1_05 = Z[3,1][0]\n",
        "stationL1_10 = Z[3,1][0]\n",
        "stationL1_15 = Z[3,1][0]\n",
        "stationL1_20 = Z[3,1][0]\n",
        "\n",
        "stationM1_05 = Z[3,1][0] \n",
        "stationM1_10 = Z[3,1][0]\n",
        "stationM1_15 = Z[3,1][0]\n",
        "stationM1_20 = Z[3,1][0]\n",
        "\n",
        "stationR1_05 = Z[3,1][0] \n",
        "stationR1_10 = Z[3,1][0]\n",
        "stationR1_15 = Z[3,1][0]\n",
        "stationR1_20 = Z[3,1][0]\n",
        "\n",
        "## Station 2\n",
        "stationL2_05 = Z[3,1][0] \n",
        "stationL2_10 = Z[3,1][0]\n",
        "stationL2_15 = Z[3,1][0]\n",
        "stationL2_20 = Z[3,1][0]\n",
        "\n",
        "\n",
        "stationM2_05 = Z[3,1][0] \n",
        "stationM2_10 = Z[3,1][0]\n",
        "stationM2_15 = Z[3,1][0]\n",
        "stationM2_20 = Z[3,1][0]\n",
        "\n",
        "stationR2_05 = Z[3,1][0] \n",
        "stationR2_10 = Z[3,1][0]\n",
        "stationR2_15 = Z[3,1][0]\n",
        "stationR2_20 = Z[3,1][0]\n",
        "\n",
        "\n",
        "## Station 3\n",
        "stationL3_05 = Z[3,1][100]\n",
        "stationL3_10 = Z[3,1][0]\n",
        "stationL3_15 = Z[3,1][0]\n",
        "stationL3_20 = Z[3,1][0]\n",
        "\n",
        "\n",
        "stationM3_05 = Z[3,1][0] \n",
        "stationM3_10 = Z[3,1][0]\n",
        "stationM3_15 = Z[3,1][0]\n",
        "stationM3_20 = Z[3,1][0]\n",
        "\n",
        "\n",
        "stationR3_05 = Z[3,1][0] \n",
        "stationR3_10 = Z[3,1][0]\n",
        "stationR3_15 = Z[3,1][0]\n",
        "stationR3_20 = Z[3,1][0]"
      ],
      "metadata": {
        "id": "5X5AsaCZMmEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rotacja wzorca oraz zaszumianie pozostałych indeksów"
      ],
      "metadata": {
        "id": "jeubyjeVaTfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rotateFrame(samples, frame, pattern):\n",
        "    temp = frame.copy()\n",
        "    temp[0:360] = [rd.uniform(3.5, 12) for _ in range(360)]\n",
        "    val = rd.randint(0, 360 - samples)\n",
        "    temp[val: val + samples] = pattern\n",
        "    return temp\n",
        "\n",
        "\n",
        "data = []\n",
        "label = []\n",
        "\n",
        "for i in range(20000):\n",
        "### Rotate station 1\n",
        "  data.append(rotateFrame(58, stationL1_05, stationL1_05_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(36, stationL1_10, stationL1_10_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(26, stationL1_15, stationL1_15_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(20, stationL1_20, stationL1_20_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(74, stationM1_05, stationM1_05_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(41, stationM1_10, stationM1_10_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(28, stationM1_15, stationM1_15_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(21, stationM1_20, stationM1_20_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(80, stationR1_05, stationR1_05_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(44, stationR1_10, stationR1_10_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(30, stationR1_15, stationR1_15_pat))\n",
        "  label.append(1)\n",
        "  data.append(rotateFrame(23, stationR1_20, stationR1_20_pat))\n",
        "  label.append(1)\n",
        "\n",
        "  ### Rotate station 2\n",
        "  data.append(rotateFrame(40, stationL2_05, stationL2_05_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(21, stationL2_10, stationL2_10_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(15, stationL2_15, stationL2_15_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(12, stationL2_20, stationL2_20_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(42, stationM2_05, stationM2_05_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(22, stationM2_10, stationM2_10_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(15, stationM2_15, stationM2_15_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(11, stationM2_20, stationM2_20_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(44, stationR2_05, stationR2_05_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(21, stationR2_10, stationR2_10_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(15, stationR2_15, stationR2_15_pat))\n",
        "  label.append(2)\n",
        "  data.append(rotateFrame(12, stationR2_20, stationR2_20_pat))\n",
        "  label.append(2)\n",
        "\n",
        "  ### Rotate station 3\n",
        "  data.append(rotateFrame(65, stationL3_05, stationL3_05_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(42, stationL3_10, stationL3_10_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(33, stationL3_15, stationL3_15_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(27, stationL3_20, stationL3_20_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(72, stationM3_05, stationM3_05_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(48, stationM3_10, stationM3_10_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(36, stationM3_15, stationM3_15_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(29, stationM3_20, stationM3_20_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(85, stationR3_05, stationR3_05_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(21, stationR3_10, stationR3_10_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(38, stationR3_15, stationR3_15_pat))\n",
        "  label.append(3)\n",
        "  data.append(rotateFrame(30, stationR3_20, stationR3_20_pat))\n",
        "  label.append(3)"
      ],
      "metadata": {
        "id": "_cuYjsBVOGpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separacja zbioru na zbiór trenujący oraz testowy"
      ],
      "metadata": {
        "id": "gdBY7U0UYngb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6mjLKTrxbcI"
      },
      "outputs": [],
      "source": [
        "X = np.array(data)\n",
        "y = np.array(label)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trenowanie modelu klasyfikującego"
      ],
      "metadata": {
        "id": "GaGd7a4AbZXT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iG74GXOL0zV"
      },
      "outputs": [],
      "source": [
        "clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(100,), random_state=1, activation= 'relu', learning_rate = 'adaptive')\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testowanie dokładności modelu"
      ],
      "metadata": {
        "id": "dy84_uBQbtX5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xw_tbawrwIZk"
      },
      "outputs": [],
      "source": [
        "clf.score(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prezentacja predykcji na zbiorze testowym"
      ],
      "metadata": {
        "id": "o28Bhpxab-Gm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRd2MC-awaWW"
      },
      "outputs": [],
      "source": [
        "clf.predict(X_test[:500000,:])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_-5ITeJ1fzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tworzenie macierzy pomyłek przy użyciu zbioru testowego"
      ],
      "metadata": {
        "id": "EcE4-1JlZuGL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmwm98i5hklG"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "Y_pred = clf.predict(X_test, )\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(y_test, Y_pred))\n",
        "print('Classification Report')\n",
        "print(classification_report(y_test, Y_pred, target_names=[\"1\", \"2\", \"3\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Zapis utworzonego modelu"
      ],
      "metadata": {
        "id": "gtPRSLnsY2ip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IdHkGRgZjuAl"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "filename = 'finalized_model.sav'\n",
        "joblib.dump(clf, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testy"
      ],
      "metadata": {
        "id": "solQ4JC8aBv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(data[0]).shape"
      ],
      "metadata": {
        "id": "1daB3I3Sb5i2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val1 = list(data)\n",
        "val2 = list(label)\n",
        "listData = list(data)\n",
        "listLabel = list(label)\n",
        "X = np.array(listData)\n",
        "y = np.array(listLabel)"
      ],
      "metadata": {
        "id": "NXs2K3TgRelQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "id": "A5emB-aqR6CL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)"
      ],
      "metadata": {
        "id": "I0aKJLvNSW31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = clf.predict(X_test, )\n",
        "y_pred = np.max(Y_pred)"
      ],
      "metadata": {
        "id": "YEmr6a-wSe8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test\n"
      ],
      "metadata": {
        "id": "oJfckN4-0XDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred"
      ],
      "metadata": {
        "id": "ddWXVmrv0YPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(y)\n"
      ],
      "metadata": {
        "id": "swp7xw8V5u1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_test)"
      ],
      "metadata": {
        "id": "WPP30Ux35wl4"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}